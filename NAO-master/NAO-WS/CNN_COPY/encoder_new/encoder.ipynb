{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "_BATCH_NORM_DECAY = 0.9\n",
    "_BATCH_NORM_EPSILON = 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder类，输入的controller的参数，模式，以及创建好的encoder所需要的参数w_emb,参数的shape是[self.vocab_size, self.emb_size],设定的vocab_size是12，分别对应一共可能出现在x中的7个I和5个OP\n",
    "\n",
    "目前不是很明白time_major的作用，为何要对x进行一次转置。解释如下：\n",
    "time_major: The shape format of the inputs and outputs Tensors. If true, these Tensors must be shaped [max_time, batch_size, depth]. If false, these Tensors must be shaped [batch_size, max_time, depth].\n",
    "\n",
    "tf.nn.dynamic_rnn 具体来说，设我们输入数据的格式为(batch_size, time_steps, input_size)，其中time_steps表示序列本身的长度，如在Char RNN中，长度为10的句子对应的time_steps就等于10。最后的input_size就表示输入数据单个序列单个时间维度上固有的长度。另外我们已经定义好了一个RNNCell，调用该RNNCell的call函数time_steps次，此时，得到的outputs就是time_steps步里所有的输出。它的形状为(batch_size, time_steps, cell.output_size)。state是最后一步的隐状态，它的形状为(batch_size, cell.state_size)。\n",
    "\n",
    "build_encoder返回的是该架构对应的code (是根据encoder_ouputs通过求平均得来的)，这个code输入进mlp(predictor)然后得出预测值，predict_value，返回的还有encoder_outputs还有state表示最后一层的隐含状态"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(object):\n",
    "    def __init__(self, params, mode, W_emb):\n",
    "        self.num_layers = params['encoder_num_layers']\n",
    "        self.hidden_size = params['encoder_hidden_size']\n",
    "        self.emb_size = params['encoder_emb_size']\n",
    "        self.mlp_num_layers = params['mlp_num_layers']\n",
    "        self.mlp_hidden_size = params['mlp_hidden_size']\n",
    "        self.mlp_dropout = params['mlp_dropout']\n",
    "        self.source_length = params['source_length']\n",
    "        self.encoder_length = params['encoder_length']\n",
    "        self.vocab_size = params['encoder_vocab_size']\n",
    "        self.dropout = params['encoder_dropout']\n",
    "        self.time_major = params['time_major']\n",
    "        self.W_emb = W_emb\n",
    "        self.mode = mode\n",
    "    \n",
    "    def build_encoder(self, x, batch_size, is_training):\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        assert x.shape.ndims == 2, '[batch_size, length]'\n",
    "        x = tf.gather(self.W_emb, x)\n",
    "        if self.source_length != self.encoder_length: #source_length [40,60] encoder_length=20\n",
    "            tf.logging.info('Concacting source sequence along depth')\n",
    "            assert self.source_length % self.encoder_length == 0\n",
    "            ratio = self.source_length // self.encoder_length\n",
    "            x = tf.reshape(x, [batch_size, self.source_length // ratio, ratio*self.emb_size])\n",
    "        if self.time_major:\n",
    "            x = tf.transpose(x, [1,0,2])\n",
    "        \n",
    "        cell_list = []\n",
    "        for i in range(self.num_layers):\n",
    "            lstm_cell = tf.contrib.rnn.LSTMCell(self.hidden_size)\n",
    "            lstm_cell = tf.contrib.rnn.DropoutWrapper(lstm_cell, output_keep_prob=1-self.dropout)\n",
    "            cell_list.append(lstm_cell)\n",
    "        if len(cell_list) == 1:\n",
    "            cell = cell_list[0]\n",
    "        else:\n",
    "            cell = tf.contrib.rnn.MultiRNNCell(cell_list)\n",
    "        initial_state = cell.zero_state(batch_size, dtype=tf.float32)\n",
    "        x, state = tf.nn.dynamic_rnn(cell, x, dtype=tf.float32, time_major=self.time_major, initial_state=initial_state)\n",
    "        x = tf.nn.l2_normalize(x, dim=-1)\n",
    "        self.encoder_outputs = x #(batch_size, time_steps, cell.output_size)\n",
    "        self.encoder_state = state\n",
    "        \n",
    "        if self.time_major:\n",
    "            x = tf.reduce_mean(x, axis=0)\n",
    "        else:\n",
    "            x = tf.reduce_mean(x, axis=1)\n",
    "            \n",
    "        #now, [batch_size, self.hidden_size]\n",
    "        x = tf.nn.l2_normalize(x, dim=-1) \n",
    "        \n",
    "        self.arch_emb = x\n",
    "        \n",
    "        for i in range(self.mlp_num_layers):\n",
    "            name = \"mlp_{}\".format(i)\n",
    "            x = tf.layers.dense(x, self.mlp_hidden_size, activation=tf.nn.relu, name=name)\n",
    "            x = tf.layer.dropout(x, self.mlp_dropout)\n",
    "            \n",
    "        self.predict_value = tf.layers.dense(x, 1, activation=tf.sigmoid, name='regression')\n",
    "        \n",
    "        \n",
    "        return {\n",
    "            'arch_emb' : self.arch_emb,\n",
    "            'predict_value': self.predict_value,\n",
    "            'encoder_outputs': self.encoder_outputs,\n",
    "            'encoder_state': self.encoder_state\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model输入encoder的input和target，controller的参数，注意这里的encoder_input代表了一batch的架构\n",
    "\n",
    "模式\n",
    "训练模式，即 mode == tf.estimator.ModeKeys.TRAIN，必须提供的是 loss 和 train_op。\n",
    "验证模式，即 mode == tf.estimator.ModeKeys.EVAL，必须提供的是 loss。\n",
    "预测模式，即 mode == tf.estimator.ModeKeys.PREDICT，必须提供的是 predicitions。\n",
    "\n",
    "build_graph函数用来构建整个计算图，其中包括了encoder网络架构的搭建，loss函数的计算\n",
    "\n",
    "目前self.build_encoder()中调用了上面的Encoder类和其类函数build—encoder\n",
    "\n",
    "self.compute_loss()也未实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, x, y, params, mode, scope='Encoder', reuse=tf.AUTO_REUSE):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.params = params\n",
    "        self.batch_size = tf.shape(x)[0]\n",
    "        self.vocab_size = params['encoder_vocab_size']\n",
    "        self.emb_size = params['encoder_emb_size']\n",
    "        self.hidden_size = params['encoder_hidden_size']\n",
    "        self.encoder_length = params['encoder_length']\n",
    "        self.weight_decay = params['weight_decay']\n",
    "        self.mode = mode\n",
    "        self.time_major = params['time_major']\n",
    "        self.is_training = self.mode == tf.estimator.ModeKeys.TRAIN\n",
    "        if not self.is_training:\n",
    "            self.params['encoder_dropout'] = 0.0\n",
    "            self.params['mlp_dropout'] = 0.0\n",
    "        \n",
    "        initializer = tf.random_uniform_initializer(-0.1,0.1)\n",
    "        tf.get_variable_scope().set_initializer(initializer)\n",
    "        self.build_graph(scope=scope, reuse=reuse)\n",
    "    \n",
    "    def build_graph(self, scope=None, reuse=tf.AUTO_REUSE):\n",
    "        tf.logging.info(\"# creating %s graph ...\" % self.mode)\n",
    "        #Encoder\n",
    "        with tf.variable_scope(scope, reuse=reuse):\n",
    "            self.W_emb = tf.get_variable('W_emb', [self.vocab_size, self.emb_size])\n",
    "            self.arch_emb, self.predict_value, self.encoder_outputs, self.encoder_state = self.build_encoder()\n",
    "            if self.mode != tf.estimator.ModeKeys.PREDICT:\n",
    "                self.compute_loss()\n",
    "            else:\n",
    "                self.loss = None\n",
    "                self.total_loss = None\n",
    "                \n",
    "    def build_encoder(self):\n",
    "        encoder = Encoder(self.params, self.mode, self.W_emb)\n",
    "        res = encoder.build_encoder(self.x, self.batch_size, self.is_training)\n",
    "        return res['arch_emb'], res['predict_value'], res['encoder_outputs'], res['encoder_state']\n",
    "    \n",
    "    def compute_loss(self):\n",
    "        weights = 1 - tf.cast(tf.equal(self.y, -1.0), tf.float32)\n",
    "        mean_squared_error = tf.losses.mean_squared_error(labels = self.y, predictions=self.predict_value, weights=weights)\n",
    "        \n",
    "        tf.identity(mean_squared_error, name='squared_error')\n",
    "        tf.summary.scalar(\"mean_squared_error\", mean_squared_error)\n",
    "        \n",
    "        #Add weight decay to the loss\n",
    "        self.loss = mean_squared_error\n",
    "        total_loss = mean_squared_error + self.weight_decay * tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n",
    "        self.total_loss = total_loss\n",
    "        \n",
    "        \n",
    "        \n",
    "    def infer(self):\n",
    "        assert self.mode == tf.estimator.ModeKeys.PREDICT\n",
    "        grads_on_outputs = tf.gradients(self.predict_value, self.encoder_outputs)[0] #(batch_size, time_steps, cell.output_size)\n",
    "        \n",
    "        new_arch_outputs = self.encoder_outputs - self.params['predict_lambda']*grads_on_outputs\n",
    "        new_arch_outputs = tf.nn.l2_normalize(new_arch_outputs, dim=-1)\n",
    "        \n",
    "        if self.time_major:\n",
    "            new_arch_emb = tf.reduce_mean(new_arch_outputs, axis=0)\n",
    "        else:\n",
    "            new_arch_emb = tf.reduce_mean(new_arch_outputs, axis=1)\n",
    "        \n",
    "        new_arch_emb = tf.nn.l2_normalize(new_arch_emb, dim=-1)\n",
    "        \n",
    "        return self.arch_emb, self.predict_value, new_arch_emb, new_arch_outputs\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
